{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1096ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b52caf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6376ca55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "physical_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb89d4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jun  3 12:23:20 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.98                 Driver Version: 535.98       CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3060 Ti   WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   55C    P8              13W / 200W |   2010MiB /  8192MiB |      6%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1740    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
      "|    0   N/A  N/A      2856    C+G   ...2txyewy\\StartMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      6240    C+G   ...0_x64__8wekyb3d8bbwe\\HxAccounts.exe    N/A      |\n",
      "|    0   N/A  N/A      7748    C+G   ...siveControlPanel\\SystemSettings.exe    N/A      |\n",
      "|    0   N/A  N/A     10004    C+G   ...oogle\\Chrome\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A     10832    C+G   ...2.0_x64__cv1g1gvanyjgm\\WhatsApp.exe    N/A      |\n",
      "|    0   N/A  N/A     19796    C+G   ...on\\113.0.1774.57\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     20128    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     21336    C+G   ....0_x64__8wekyb3d8bbwe\\HxOutlook.exe    N/A      |\n",
      "|    0   N/A  N/A     21412    C+G   ...GeForce Experience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A     22120    C+G   ...on\\113.0.1774.57\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     22980      C   C:\\Users\\Maruata\\anaconda3\\python.exe     N/A      |\n",
      "|    0   N/A  N/A     23028    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe    N/A      |\n",
      "|    0   N/A  N/A     24032    C+G   ...8bbwe\\SnippingTool\\SnippingTool.exe    N/A      |\n",
      "|    0   N/A  N/A     24972    C+G   ...m Files\\Mozilla Firefox\\firefox.exe    N/A      |\n",
      "|    0   N/A  N/A     24984    C+G   ...aam7r\\AcrobatNotificationClient.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1335dc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    'Src IP': 'category',\n",
    "    'Src Port': 'uint16',\n",
    "    'Dst IP': 'category',\n",
    "    'Dst Port': 'uint16',\n",
    "    'Protocol': 'category',\n",
    "    'Flow Duration': 'uint32',\n",
    "    'Tot Fwd Pkts': 'uint32',\n",
    "    'Tot Bwd Pkts': 'uint32',\n",
    "    'TotLen Fwd Pkts': 'float32',\n",
    "    'TotLen Bwd Pkts': 'float32',\n",
    "    'Fwd Pkt Len Max': 'float32',\n",
    "    'Fwd Pkt Len Min': 'float32',\n",
    "    'Fwd Pkt Len Mean': 'float32',\n",
    "    'Fwd Pkt Len Std': 'float32',\n",
    "    'Bwd Pkt Len Max': 'float32',\n",
    "    'Bwd Pkt Len Min': 'float32',\n",
    "    'Bwd Pkt Len Mean': 'float32',\n",
    "    'Bwd Pkt Len Std': 'float32',\n",
    "    'Flow Byts/s': 'float32',\n",
    "    'Flow Pkts/s': 'float32',\n",
    "    'Flow IAT Mean': 'float32',\n",
    "    'Flow IAT Std': 'float32',\n",
    "    'Flow IAT Max': 'float32',\n",
    "    'Flow IAT Min': 'float32',\n",
    "    'Fwd IAT Tot': 'float32',\n",
    "    'Fwd IAT Mean': 'float32',\n",
    "    'Fwd IAT Std': 'float32',\n",
    "    'Fwd IAT Max': 'float32',\n",
    "    'Fwd IAT Min': 'float32',\n",
    "    'Bwd IAT Tot': 'float32',\n",
    "    'Bwd IAT Mean': 'float32',\n",
    "    'Bwd IAT Std': 'float32',\n",
    "    'Bwd IAT Max': 'float32',\n",
    "    'Bwd IAT Min': 'float32',\n",
    "    'Fwd PSH Flags': 'category',\n",
    "    'Bwd PSH Flags': 'category',\n",
    "    'Fwd URG Flags': 'category',\n",
    "    'Bwd URG Flags': 'category',\n",
    "    'Fwd Header Len': 'uint32',\n",
    "    'Bwd Header Len': 'uint32',\n",
    "    'Fwd Pkts/s': 'float32',\n",
    "    'Bwd Pkts/s': 'float32',\n",
    "    'Pkt Len Min': 'float32',\n",
    "    'Pkt Len Max': 'float32',\n",
    "    'Pkt Len Mean': 'float32',\n",
    "    'Pkt Len Std': 'float32',\n",
    "    'Pkt Len Var': 'float32',\n",
    "    'FIN Flag Cnt': 'category',\n",
    "    'SYN Flag Cnt': 'category',\n",
    "    'RST Flag Cnt': 'category',\n",
    "    'PSH Flag Cnt': 'category',\n",
    "    'ACK Flag Cnt': 'category',\n",
    "    'URG Flag Cnt': 'category',\n",
    "    'CWE Flag Count': 'category',\n",
    "    'ECE Flag Cnt': 'category',\n",
    "    'Down/Up Ratio': 'float32',\n",
    "    'Pkt Size Avg': 'float32',\n",
    "    'Fwd Seg Size Avg': 'float32',\n",
    "    'Bwd Seg Size Avg': 'float32',\n",
    "    'Fwd Byts/b Avg': 'uint32',\n",
    "    'Fwd Pkts/b Avg': 'uint32',\n",
    "    'Fwd Blk Rate Avg': 'uint32',\n",
    "    'Bwd Byts/b Avg': 'uint32',\n",
    "    'Bwd Pkts/b Avg': 'uint32',\n",
    "    'Bwd Blk Rate Avg': 'uint32',\n",
    "    'Subflow Fwd Pkts': 'uint32',\n",
    "    'Subflow Fwd Byts': 'uint32',\n",
    "    'Subflow Bwd Pkts': 'uint32',\n",
    "    'Subflow Bwd Byts': 'uint32',\n",
    "    'Init Fwd Win Byts': 'uint32',\n",
    "    'Init Bwd Win Byts': 'uint32',\n",
    "    'Fwd Act Data Pkts': 'uint32',\n",
    "    'Fwd Seg Size Min': 'uint32',\n",
    "    'Active Mean': 'float32',\n",
    "    'Active Std': 'float32',\n",
    "    'Active Max': 'float32',\n",
    "    'Active Min': 'float32',\n",
    "    'Idle Mean': 'float32',\n",
    "    'Idle Std': 'float32',\n",
    "    'Idle Max': 'float32',\n",
    "    'Idle Min': 'float32',\n",
    "    'Label': 'category'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4eb454f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.10  # 10% of the data\n",
    "\n",
    "df = pd.read_csv('H:/Datasets/kaggle_ddos/final_dataset.csv', dtype=dtypes, \n",
    "                 skiprows=lambda i: i>0 and random.random() > p, low_memory=False)\n",
    "del dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98c25a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Flow ID</th>\n",
       "      <th>Src IP</th>\n",
       "      <th>Src Port</th>\n",
       "      <th>Dst IP</th>\n",
       "      <th>Dst Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Tot Fwd Pkts</th>\n",
       "      <th>...</th>\n",
       "      <th>Fwd Seg Size Min</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>831</td>\n",
       "      <td>192.168.4.118-203.73.24.75-4529-80-6</td>\n",
       "      <td>192.168.4.118</td>\n",
       "      <td>4529</td>\n",
       "      <td>203.73.24.75</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>12/06/2010 08:36:45 AM</td>\n",
       "      <td>135</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ddos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>856</td>\n",
       "      <td>192.168.4.118-203.73.24.75-4533-80-6</td>\n",
       "      <td>192.168.4.118</td>\n",
       "      <td>4533</td>\n",
       "      <td>203.73.24.75</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>12/06/2010 08:36:58 AM</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ddos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>881</td>\n",
       "      <td>192.168.4.118-203.73.24.75-4541-80-6</td>\n",
       "      <td>192.168.4.118</td>\n",
       "      <td>4541</td>\n",
       "      <td>203.73.24.75</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>12/06/2010 08:37:07 AM</td>\n",
       "      <td>478574</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ddos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>887</td>\n",
       "      <td>192.168.4.118-203.73.24.75-4543-80-6</td>\n",
       "      <td>192.168.4.118</td>\n",
       "      <td>4543</td>\n",
       "      <td>203.73.24.75</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>12/06/2010 08:37:08 AM</td>\n",
       "      <td>1242607</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ddos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>937</td>\n",
       "      <td>192.168.1.103-97.74.144.108-1722-80-6</td>\n",
       "      <td>192.168.1.103</td>\n",
       "      <td>1722</td>\n",
       "      <td>97.74.144.108</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>12/06/2010 08:37:23 AM</td>\n",
       "      <td>1859292</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ddos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                Flow ID         Src IP  Src Port  \\\n",
       "0         831   192.168.4.118-203.73.24.75-4529-80-6  192.168.4.118      4529   \n",
       "1         856   192.168.4.118-203.73.24.75-4533-80-6  192.168.4.118      4533   \n",
       "2         881   192.168.4.118-203.73.24.75-4541-80-6  192.168.4.118      4541   \n",
       "3         887   192.168.4.118-203.73.24.75-4543-80-6  192.168.4.118      4543   \n",
       "4         937  192.168.1.103-97.74.144.108-1722-80-6  192.168.1.103      1722   \n",
       "\n",
       "          Dst IP  Dst Port Protocol               Timestamp  Flow Duration  \\\n",
       "0   203.73.24.75        80        6  12/06/2010 08:36:45 AM            135   \n",
       "1   203.73.24.75        80        6  12/06/2010 08:36:58 AM             91   \n",
       "2   203.73.24.75        80        6  12/06/2010 08:37:07 AM         478574   \n",
       "3   203.73.24.75        80        6  12/06/2010 08:37:08 AM        1242607   \n",
       "4  97.74.144.108        80        6  12/06/2010 08:37:23 AM        1859292   \n",
       "\n",
       "   Tot Fwd Pkts  ...  Fwd Seg Size Min  Active Mean  Active Std  Active Max  \\\n",
       "0             1  ...                 0          0.0         0.0         0.0   \n",
       "1             1  ...                 0          0.0         0.0         0.0   \n",
       "2             2  ...                 0          0.0         0.0         0.0   \n",
       "3             9  ...                 0          0.0         0.0         0.0   \n",
       "4             1  ...                 0          0.0         0.0         0.0   \n",
       "\n",
       "   Active Min  Idle Mean  Idle Std  Idle Max  Idle Min  Label  \n",
       "0         0.0        0.0       0.0       0.0       0.0   ddos  \n",
       "1         0.0        0.0       0.0       0.0       0.0   ddos  \n",
       "2         0.0        0.0       0.0       0.0       0.0   ddos  \n",
       "3         0.0        0.0       0.0       0.0       0.0   ddos  \n",
       "4         0.0        0.0       0.0       0.0       0.0   ddos  \n",
       "\n",
       "[5 rows x 85 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1864083e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Src Port</th>\n",
       "      <th>Dst Port</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Tot Fwd Pkts</th>\n",
       "      <th>Tot Bwd Pkts</th>\n",
       "      <th>TotLen Fwd Pkts</th>\n",
       "      <th>TotLen Bwd Pkts</th>\n",
       "      <th>Fwd Pkt Len Max</th>\n",
       "      <th>Fwd Pkt Len Min</th>\n",
       "      <th>...</th>\n",
       "      <th>Fwd Act Data Pkts</th>\n",
       "      <th>Fwd Seg Size Min</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.278011e+06</td>\n",
       "      <td>1.278011e+06</td>\n",
       "      <td>1.278011e+06</td>\n",
       "      <td>1.278011e+06</td>\n",
       "      <td>1.278011e+06</td>\n",
       "      <td>1.278011e+06</td>\n",
       "      <td>1.278011e+06</td>\n",
       "      <td>1.278011e+06</td>\n",
       "      <td>1.278011e+06</td>\n",
       "      <td>1.278011e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.278011e+06</td>\n",
       "      <td>1.278011e+06</td>\n",
       "      <td>1.278011e+06</td>\n",
       "      <td>1.278011e+06</td>\n",
       "      <td>1.278011e+06</td>\n",
       "      <td>1.278011e+06</td>\n",
       "      <td>1.278011e+06</td>\n",
       "      <td>1.278011e+06</td>\n",
       "      <td>1.278011e+06</td>\n",
       "      <td>1.278011e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.661006e+06</td>\n",
       "      <td>3.709751e+04</td>\n",
       "      <td>1.464420e+04</td>\n",
       "      <td>8.184938e+06</td>\n",
       "      <td>2.342330e+01</td>\n",
       "      <td>5.290649e+00</td>\n",
       "      <td>9.985665e+02</td>\n",
       "      <td>4.002615e+03</td>\n",
       "      <td>2.905067e+02</td>\n",
       "      <td>7.105572e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.015726e+01</td>\n",
       "      <td>8.114008e+00</td>\n",
       "      <td>1.375589e+05</td>\n",
       "      <td>6.887883e+04</td>\n",
       "      <td>2.052405e+05</td>\n",
       "      <td>9.125988e+04</td>\n",
       "      <td>3.114652e+06</td>\n",
       "      <td>1.078926e+05</td>\n",
       "      <td>3.208799e+06</td>\n",
       "      <td>3.014922e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.168704e+06</td>\n",
       "      <td>2.522040e+04</td>\n",
       "      <td>2.306760e+04</td>\n",
       "      <td>2.499296e+07</td>\n",
       "      <td>1.558811e+03</td>\n",
       "      <td>3.435476e+02</td>\n",
       "      <td>4.919768e+04</td>\n",
       "      <td>8.104006e+05</td>\n",
       "      <td>3.933541e+02</td>\n",
       "      <td>1.969757e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.537056e+03</td>\n",
       "      <td>9.136056e+00</td>\n",
       "      <td>2.307885e+06</td>\n",
       "      <td>1.394569e+06</td>\n",
       "      <td>3.051797e+06</td>\n",
       "      <td>1.947192e+06</td>\n",
       "      <td>1.220125e+07</td>\n",
       "      <td>1.395475e+06</td>\n",
       "      <td>1.245570e+07</td>\n",
       "      <td>1.209093e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.979560e+05</td>\n",
       "      <td>4.430000e+02</td>\n",
       "      <td>8.000000e+01</td>\n",
       "      <td>1.261000e+03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.039471e+06</td>\n",
       "      <td>5.059700e+04</td>\n",
       "      <td>8.000000e+01</td>\n",
       "      <td>3.185200e+04</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.200000e+01</td>\n",
       "      <td>1.120000e+02</td>\n",
       "      <td>4.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.897440e+06</td>\n",
       "      <td>5.624000e+04</td>\n",
       "      <td>3.853000e+04</td>\n",
       "      <td>4.157535e+06</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>9.350000e+02</td>\n",
       "      <td>3.580000e+02</td>\n",
       "      <td>6.770000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.902448e+06</td>\n",
       "      <td>6.553500e+04</td>\n",
       "      <td>6.553400e+04</td>\n",
       "      <td>4.294967e+09</td>\n",
       "      <td>2.373490e+05</td>\n",
       "      <td>2.839010e+05</td>\n",
       "      <td>7.595168e+06</td>\n",
       "      <td>6.296003e+08</td>\n",
       "      <td>1.606000e+04</td>\n",
       "      <td>1.472000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>2.373490e+05</td>\n",
       "      <td>4.400000e+01</td>\n",
       "      <td>1.112835e+08</td>\n",
       "      <td>6.879098e+07</td>\n",
       "      <td>1.112835e+08</td>\n",
       "      <td>1.112835e+08</td>\n",
       "      <td>1.199882e+08</td>\n",
       "      <td>7.599266e+07</td>\n",
       "      <td>1.199882e+08</td>\n",
       "      <td>1.199882e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0      Src Port      Dst Port  Flow Duration  Tot Fwd Pkts  \\\n",
       "count  1.278011e+06  1.278011e+06  1.278011e+06   1.278011e+06  1.278011e+06   \n",
       "mean   2.661006e+06  3.709751e+04  1.464420e+04   8.184938e+06  2.342330e+01   \n",
       "std    2.168704e+06  2.522040e+04  2.306760e+04   2.499296e+07  1.558811e+03   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00   0.000000e+00  0.000000e+00   \n",
       "25%    8.979560e+05  4.430000e+02  8.000000e+01   1.261000e+03  1.000000e+00   \n",
       "50%    2.039471e+06  5.059700e+04  8.000000e+01   3.185200e+04  2.000000e+00   \n",
       "75%    3.897440e+06  5.624000e+04  3.853000e+04   4.157535e+06  4.000000e+00   \n",
       "max    7.902448e+06  6.553500e+04  6.553400e+04   4.294967e+09  2.373490e+05   \n",
       "\n",
       "       Tot Bwd Pkts  TotLen Fwd Pkts  TotLen Bwd Pkts  Fwd Pkt Len Max  \\\n",
       "count  1.278011e+06     1.278011e+06     1.278011e+06     1.278011e+06   \n",
       "mean   5.290649e+00     9.985665e+02     4.002615e+03     2.905067e+02   \n",
       "std    3.435476e+02     4.919768e+04     8.104006e+05     3.933541e+02   \n",
       "min    0.000000e+00     0.000000e+00     0.000000e+00     0.000000e+00   \n",
       "25%    1.000000e+00     0.000000e+00     0.000000e+00     0.000000e+00   \n",
       "50%    1.000000e+00     4.200000e+01     1.120000e+02     4.000000e+01   \n",
       "75%    4.000000e+00     9.350000e+02     3.580000e+02     6.770000e+02   \n",
       "max    2.839010e+05     7.595168e+06     6.296003e+08     1.606000e+04   \n",
       "\n",
       "       Fwd Pkt Len Min  ...  Fwd Act Data Pkts  Fwd Seg Size Min  \\\n",
       "count     1.278011e+06  ...       1.278011e+06      1.278011e+06   \n",
       "mean      7.105572e+00  ...       2.015726e+01      8.114008e+00   \n",
       "std       1.969757e+01  ...       1.537056e+03      9.136056e+00   \n",
       "min       0.000000e+00  ...       0.000000e+00      0.000000e+00   \n",
       "25%       0.000000e+00  ...       0.000000e+00      0.000000e+00   \n",
       "50%       0.000000e+00  ...       0.000000e+00      0.000000e+00   \n",
       "75%       0.000000e+00  ...       1.000000e+00      2.000000e+01   \n",
       "max       1.472000e+03  ...       2.373490e+05      4.400000e+01   \n",
       "\n",
       "        Active Mean    Active Std    Active Max    Active Min     Idle Mean  \\\n",
       "count  1.278011e+06  1.278011e+06  1.278011e+06  1.278011e+06  1.278011e+06   \n",
       "mean   1.375589e+05  6.887883e+04  2.052405e+05  9.125988e+04  3.114652e+06   \n",
       "std    2.307885e+06  1.394569e+06  3.051797e+06  1.947192e+06  1.220125e+07   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "max    1.112835e+08  6.879098e+07  1.112835e+08  1.112835e+08  1.199882e+08   \n",
       "\n",
       "           Idle Std      Idle Max      Idle Min  \n",
       "count  1.278011e+06  1.278011e+06  1.278011e+06  \n",
       "mean   1.078926e+05  3.208799e+06  3.014922e+06  \n",
       "std    1.395475e+06  1.245570e+07  1.209093e+07  \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "25%    0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "50%    0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "75%    0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "max    7.599266e+07  1.199882e+08  1.199882e+08  \n",
       "\n",
       "[8 rows x 67 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7163915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1278011, 85)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "641d7244",
   "metadata": {},
   "outputs": [],
   "source": [
    "colsToDrop = np.array(['Src IP', 'Dst IP', 'Fwd Byts/b Avg', 'Fwd Pkts/b Avg', 'Fwd Blk Rate Avg', \n",
    "                       'Bwd Byts/b Avg', 'Bwd Pkts/b Avg', 'Bwd Blk Rate Avg', 'Flow ID', 'Timestamp', 'Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "006c45b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'label': 'Label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82895328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ddos      646389\n",
       "Benign    631622\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fed0dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA44AAAHSCAYAAACjJJUxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAsvUlEQVR4nO3dffxlZV0v/M9XBpFQEETnEKBooqWSphPasTpjFKDZ0UoLHwfDuDN7lLtzsFORGufW7mOWlholilQqWt6QZkropJ58AE0P4kNMikiQqIM8Jcrg9/5jr9Ht+Js1v5lhz96/37zfr9d+7b2uta5rf/fMi734zLXWtau7AwAAANtzh3kXAAAAwGITHAEAABglOAIAADBKcAQAAGCU4AgAAMAowREAAIBRgiMAq0JVvbKqfvt2GuueVXVTVe0zbG+sqmfeHmMP472tqjbcXuPtxPv+XlV9sar+fU+/NwArm+AIwMKrqiuq6itVdWNVfbmq/qmqfqGqvnEe6+5f6O4XLHOsHx07pruv7O47d/dtt0Ptv1tVf7HN+I/u7nN2d+ydrOPIJKcleUB3/6cl9q+vqq8Pgfmmqrqqqs6rqu/fiff4ts8KwOogOAKwUvxEd98lyb2SvDDJf0/yqtv7Tapqze095oK4V5Ivdfe1I8dc3d13TnKXJI9I8skk76mq4/ZEgQAsLsERgBWlu6/v7guS/GySDVX1oCSpqtdU1e8Nrw+tqrcMs5Obq+o9VXWHqjo3yT2T/O0wq/bfquqoquqqOqWqrkzyzqm26RD5XVX1waq6vqrOr6pDhvdaX1VXTde4dVazqk5M8ptJfnZ4v48O+79x6etQ129V1Wer6tqqem1VHTTs21rHhqq6crjM9H9s78+mqg4a+n9hGO+3hvF/NMmFSb5zqOM1O/gz7u6+qrt/J8mfJ3nR1Hv8UVV9rqpuqKoPVdUPDe3b+6zPqKpPDLPFn66q/2vsvQFYTIIjACtSd38wyVVJfmiJ3acN++6eZG0mgaa7+2lJrsxk9vLO3f37U33+S5LvSXLCdt7y6Ul+Lsl3JtmS5KXLqPHvk/zPJG8Y3u/BSxx28vB4VJL7JLlzkj/e5pgfTHL/JMcl+Z2q+p7tvOXLkhw0jPNfhpqf0d3/kOTRGWYUu/vkHdU+5W+SPLSqDhi2L07ykCSHJPmrJG+sqjuNfNZrkzw2yYFJnpHkJVX10J14fwAWgOAIwEp2dSYBZlu3Jjksyb26+9bufk939w7G+t3uvrm7v7Kd/ed298e6++Ykv53kZ7YunrObnpLkD7r70919U5LnJjlpm9nO53X3V7r7o0k+muTbAuhQy88meW5339jdVyR5cZKn7WZ9VyepJHdNku7+i+7+Undv6e4XJ9kvk1C7pO5+a3f/6zCL+Y9J3pGlwz4AC0xwBGAlOzzJ5iXa/98km5K8Y7g88vRljPW5ndj/2ST7Jjl0WVWO+85hvOmx12QyU7rV9Cqo/5HJrOS2Dk1yxyXGOnw36zs8SSf5cpJU1WnDpafXV9WXM5nh3O6fQ1U9uqreP1wy/OUkjxk7HoDFJDgCsCINq30enuS92+4bZtxO6+77JPmJJM+ZWuBlezOPO5qRPHLq9T0zmdX8YpKbk3zHVF37ZHKJ7HLHvTqThWumx96S5PM76LetLw41bTvWv+3kONv6ySQf7u6bh/sZ/3uSn0lycHffNcn1mcxIJtt81qraL8lfJ/lfSdYOx//d1PEArBCCIwArSlUdWFWPTfL6JH/R3Zcuccxjq+q+VVVJbkhy2/BIJoHsPrvw1k+tqgdU1XckeX6SNw0/1/EvSe5UVT9eVfsm+a1MLt/c6vNJjpr+6ZBtvC7Jr1fVvavqzvnmfYJbdqa4oZbzkpxZVXepqnsleU6Snf55jJo4vKrOSPLMTO4RTSarrW5J8oUka6rqdzK5d3GrbT/rHTP5s/hCki1V9egkx+9sPQDMn+AIwErxt1V1YyaXjP6PJH+QyWIrSzk6yT8kuSnJ+5K8vLs3Dvv+nyS/Nay4+n/vxPufm+Q1mVw2eqckv5JMVnlN8ouZrD76b5nMQE6vsvrG4flLVfXhJcY9exj73Uk+k+SWJL+8E3VN++Xh/T+dyUzsXw3jL9d3VtVNmfy5XZzkmCTru/sdw/63J3lbJmH5s0Ot05fwfstn7e4bM/lzOi/JdUmenOSCXfhcAMxZ7XitAAAAAPZmZhwBAAAYJTgCAAAwSnAEAABglOAIAADAqDXzLmBRHHrooX3UUUfNuwxY0W6++eYccMAB8y4DgL2U8xDsng996ENf7O67L7VPcBwcddRRueSSS+ZdBqxoGzduzPr16+ddBgB7Kech2D1V9dnt7XOpKgAAAKMERwAAAEYJjgAAAIwSHAEAABglOAIAADBKcAQAAGCU4AgAAMAowREAAIBRgiMAAACjBEcAAABGCY4AAACMEhwBAAAYJTgCAAAwSnAEAABglOAIAADAKMERAACAUWvmXQAs11Gnv3XeJbADpx2zJSf7e1pYV7zwx+ddAgCwQplxBAAAYJTgCAAAwCjBEQAAgFGCIwAAAKMERwAAAEYJjgAAAIwSHAEAABglOAIAADBqzbwLAABYKY46/a3zLoERpx2zJSf7O1poV7zwx+ddArvIjCMAAACjBEcAAABGCY4AAACMEhwBAAAYJTgCAAAwSnAEAABglOAIAADAKMERAACAUYIjAAAAowRHAAAARgmOAAAAjBIcAQAAGCU4AgAAMGqmwbGq7lpVb6qqT1bVJ6rqB6rqkKq6sKouH54Pnjr+uVW1qao+VVUnTLU/rKouHfa9tKpqaN+vqt4wtH+gqo6a6rNheI/Lq2rDLD8nAADAajbrGcc/SvL33f3dSR6c5BNJTk9yUXcfneSiYTtV9YAkJyV5YJITk7y8qvYZxnlFklOTHD08ThzaT0lyXXffN8lLkrxoGOuQJGckeXiSY5OcMR1QAQAAWL6ZBceqOjDJDyd5VZJ099e6+8tJHpfknOGwc5I8fnj9uCSv7+6vdvdnkmxKcmxVHZbkwO5+X3d3ktdu02frWG9KctwwG3lCkgu7e3N3X5fkwnwzbAIAALAT1sxw7Psk+UKSV1fVg5N8KMmvJlnb3dckSXdfU1X3GI4/PMn7p/pfNbTdOrzetn1rn88NY22pquuT3G26fYk+31BVp2Yyk5m1a9dm48aNu/pZ2QNOO2bLvEtgB9bu7+9pkfmOg93nO26xOQ8tPueilWuWwXFNkocm+eXu/kBV/VGGy1K3o5Zo65H2Xe3zzYbus5KclSTr1q3r9evXj5THvJ18+lvnXQI7cNoxW/LiS2f5tcLuuOIp6+ddAqx4zkWLzXlo8TkXrVyzvMfxqiRXdfcHhu03ZRIkPz9cfprh+dqp44+c6n9EkquH9iOWaP+WPlW1JslBSTaPjAUAAMBOmllw7O5/T/K5qrr/0HRcko8nuSDJ1lVONyQ5f3h9QZKThpVS753JIjgfHC5rvbGqHjHcv/j0bfpsHesJSd453Af59iTHV9XBw6I4xw9tAAAA7KRZz+X/cpK/rKo7Jvl0kmdkElbPq6pTklyZ5IlJ0t2XVdV5mYTLLUme3d23DeM8K8lrkuyf5G3DI5ksvHNuVW3KZKbxpGGszVX1giQXD8c9v7s3z/KDAgAArFYzDY7d/ZEk65bYddx2jj8zyZlLtF+S5EFLtN+SIXguse/sJGfvRLkAAAAsYda/4wgAAMAKJzgCAAAwSnAEAABglOAIAADAKMERAACAUYIjAAAAowRHAAAARgmOAAAAjBIcAQAAGCU4AgAAMEpwBAAAYJTgCAAAwCjBEQAAgFGCIwAAAKMERwAAAEYJjgAAAIwSHAEAABglOAIAADBKcAQAAGCU4AgAAMAowREAAIBRgiMAAACjBEcAAABGCY4AAACMEhwBAAAYJTgCAAAwSnAEAABglOAIAADAKMERAACAUYIjAAAAowRHAAAARgmOAAAAjBIcAQAAGCU4AgAAMEpwBAAAYJTgCAAAwCjBEQAAgFGCIwAAAKMERwAAAEYJjgAAAIwSHAEAABglOAIAADBKcAQAAGCU4AgAAMAowREAAIBRgiMAAACjBEcAAABGzTQ4VtUVVXVpVX2kqi4Z2g6pqgur6vLh+eCp459bVZuq6lNVdcJU+8OGcTZV1Uurqob2/arqDUP7B6rqqKk+G4b3uLyqNszycwIAAKxme2LG8VHd/ZDuXjdsn57kou4+OslFw3aq6gFJTkrywCQnJnl5Ve0z9HlFklOTHD08ThzaT0lyXXffN8lLkrxoGOuQJGckeXiSY5OcMR1QAQAAWL55XKr6uCTnDK/PSfL4qfbXd/dXu/szSTYlObaqDktyYHe/r7s7yWu36bN1rDclOW6YjTwhyYXdvbm7r0tyYb4ZNgEAANgJa2Y8fid5R1V1kj/t7rOSrO3ua5Kku6+pqnsMxx6e5P1Tfa8a2m4dXm/bvrXP54axtlTV9UnuNt2+RJ9vqKpTM5nJzNq1a7Nx48Zd/6TM3GnHbJl3CezA2v39PS0y33Gw+3zHLTbnocXnXLRyzTo4PrK7rx7C4YVV9cmRY2uJth5p39U+32yYBNmzkmTdunW9fv36kfKYt5NPf+u8S2AHTjtmS1586ay/VthVVzxl/bxLgBXPuWixOQ8tPueilWuml6p299XD87VJ3pzJ/YafHy4/zfB87XD4VUmOnOp+RJKrh/Yjlmj/lj5VtSbJQUk2j4wFAADATppZcKyqA6rqLltfJzk+yceSXJBk6yqnG5KcP7y+IMlJw0qp985kEZwPDpe13lhVjxjuX3z6Nn22jvWEJO8c7oN8e5Ljq+rgYVGc44c2AAAAdtIs5/LXJnnz8MsZa5L8VXf/fVVdnOS8qjolyZVJnpgk3X1ZVZ2X5ONJtiR5dnffNoz1rCSvSbJ/krcNjyR5VZJzq2pTJjONJw1jba6qFyS5eDju+d29eYafFQAAYNWaWXDs7k8nefAS7V9Kctx2+pyZ5Mwl2i9J8qAl2m/JEDyX2Hd2krN3rmoAAAC2NY+f4wAAAGAFERwBAAAYJTgCAAAwSnAEAABglOAIAADAKMERAACAUYIjAAAAowRHAAAARgmOAAAAjBIcAQAAGCU4AgAAMEpwBAAAYJTgCAAAwCjBEQAAgFGCIwAAAKMERwAAAEYJjgAAAIwSHAEAABglOAIAADBKcAQAAGCU4AgAAMAowREAAIBRgiMAAACjBEcAAABGCY4AAACMEhwBAAAYJTgCAAAwSnAEAABglOAIAADAKMERAACAUYIjAAAAowRHAAAARgmOAAAAjNqp4FhVB1fV986qGAAAABbPDoNjVW2sqgOr6pAkH03y6qr6g9mXBgAAwCJYzozjQd19Q5KfSvLq7n5Ykh+dbVkAAAAsiuUExzVVdViSn0nylhnXAwAAwIJZTnB8fpK3J9nU3RdX1X2SXD7bsgAAAFgUa3Z0QHe/Mckbp7Y/neSnZ1kUAAAAi2M5i+P8/rA4zr5VdVFVfbGqnronigMAAGD+lnOp6vHD4jiPTXJVkvsl+Y2ZVgUAAMDCWE5w3Hd4fkyS13X35hnWAwAAwILZ4T2OSf62qj6Z5CtJfrGq7p7kltmWBQAAwKLY4Yxjd5+e5AeSrOvuW5PcnORxsy4MAACAxbCcGcckOTzJj1XVnabaXjuDegAAAFgwOwyOVXVGkvVJHpDk75I8Osl7IzgCAADsFZazOM4TkhyX5N+7+xlJHpxkv5lWBQAAwMJYTnD8Snd/PcmWqjowybVJ7rPcN6iqfarqn6vqLcP2IVV1YVVdPjwfPHXsc6tqU1V9qqpOmGp/WFVdOux7aVXV0L5fVb1haP9AVR011WfD8B6XV9WG5dYLAADAt1pOcLykqu6a5M+SfCjJh5N8cCfe41eTfGJq+/QkF3X30UkuGrZTVQ9IclKSByY5McnLq2qfoc8rkpya5OjhceLQfkqS67r7vklekuRFw1iHJDkjycOTHJvkjOmACgAAwPItZ1XVX+zuL3f3K5P8WJINwyWrO1RVRyT58SR/PtX8uCTnDK/PSfL4qfbXd/dXu/szSTYlObaqDktyYHe/r7s7k3srH7/EWG9KctwwG3lCkgu7e3N3X5fkwnwzbAIAALATtrs4TlU9dGxfd394GeP/YZL/luQuU21ru/uaJOnua6rqHkP74UneP3XcVUPbrcPrbdu39vncMNaWqro+yd2m25foAwAAwE4YW1X1xSP7OsmPjA1cVY9Ncm13f6iq1i+jltrO+2yvfVf7TNd4aiaXwGbt2rXZuHHjMspkXk47Zsu8S2AH1u7v72mR+Y6D3ec7brE5Dy0+56KVa7vBsbsftZtjPzLJf62qxyS5U5IDq+ovkny+qg4bZhsPy2SxnWQyK3jkVP8jklw9tB+xRPt0n6uqak2Sg5JsHtrXb9Nn47YFdvdZSc5KknXr1vX69eu3PYQFcvLpb513CezAacdsyYsvXe7Pw7KnXfGU9fMuAVY856LF5jy0+JyLVq7t3uNYVU+tqqct0f7zVfXkHQ3c3c/t7iO6+6hMFr15Z3c/NckFSbaucrohyfnD6wuSnDSslHrvTBbB+eBwWeuNVfWI4f7Fp2/TZ+tYTxjeo5O8PcnxVXXwsCjO8UMbAAAAO2nsn2ROS/LDS7S/Icm7kvzVLr7nC5OcV1WnJLkyyROTpLsvq6rzknw8yZYkz+7u24Y+z0rymiT7J3nb8EiSVyU5t6o2ZTLTeNIw1uaqekGSi4fjnt/dm3exXgAAgL3aWHDcp7tv3Laxu2+oqn135k26e2OGS0W7+0tJjtvOcWcmOXOJ9kuSPGiJ9lsyBM8l9p2d5OydqRMAAIBvN/ZzHPtW1QHbNlbVXZLccXYlAQAAsEjGguOrkrypqo7a2jC8fv2wDwAAgL3A2Kqq/6uqbkryj1V150x+zuLmJC/s7lfsqQIBAACYr9H1irv7lUleOQTHWuqeRwAAAFa3Zf3QTXffNOtCAAAAWExj9zgCAADAeHCsqjtU1X/eU8UAAACweEaDY3d/PcmL91AtAAAALKDlXKr6jqr66aqqmVcDAADAwlnO4jjPSXJAktuq6itJKkl394EzrQwAAICFsMPg2N132ROFAAAAsJh2eKlqTTy1qn572D6yqo6dfWkAAAAsguXc4/jyJD+Q5MnD9k1J/mRmFQEAALBQlnOP48O7+6FV9c9J0t3XVdUdZ1wXAAAAC2I5M463VtU+STpJquruSb4+06oAAABYGMsJji9N8uYka6vqzCTvTfI/Z1oVAAAAC2M5q6r+ZVV9KMlxQ9Pju/sTsy0LAACARbGcexyT5DuSbL1cdf/ZlQMAAMCiWc7PcfxOknOSHJLk0CSvrqrfmnVhAAAALIblzDg+Kcn3dfctSVJVL0zy4SS/N8vCAAAAWAzLWRzniiR3mtreL8m/zqQaAAAAFs5yZhy/muSyqrowk3scfyzJe6vqpUnS3b8yw/oAAACYs+UExzcPj602zqYUAAAAFtFyfo7jnD1RCAAAAItpOfc4AgAAsBcTHAEAABi1U8Gxqu5QVQfOqhgAAAAWzw6DY1X9VVUdWFUHJPl4kk9V1W/MvjQAAAAWwXJmHB/Q3TckeXySv0tyzyRPm2VRAAAALI7lBMd9q2rfTILj+d1962xLAgAAYJEsJzj+aZIrkhyQ5N1Vda8k18+yKAAAABbHcoLj33b34d39mO7uJFcm+bkZ1wUAAMCCWE5w/OvpjSE8vn425QAAALBo1mxvR1V9d5IHJjmoqn5qateBSe4068IAAABYDNsNjknun+SxSe6a5Cem2m9M8vMzrAkAAIAFst3g2N3nJzm/qn6gu9+3B2sCAABggYzNOG61qap+M8lR08d3twVyAAAA9gLLCY7nJ3lPkn9IcttsywEAAGDRLCc4fkd3//eZVwIAAMBCWs7Pcbylqh4z80oAAABYSMsJjr+aSXj8SlXdUFU3VtUNsy4MAACAxbDDS1W7+y57ohAAAAAW03aDY1V9d3d/sqoeutT+7v7w7MoCAABgUYzNOD4nyalJXrzEvk7yIzOpCAAAgIWy3eDY3acOz4/ac+UAAACwaHZ4j2NV7ZvkWUl+eGjamORPu/vWGdYFAADAgljO7zi+Ism+SV4+bD9taHvmrIoCAABgcSwnOH5/dz94avudVfXRWRUEAADAYlnO7zjeVlXftXWjqu6T5LYddaqqO1XVB6vqo1V1WVU9b2g/pKourKrLh+eDp/o8t6o2VdWnquqEqfaHVdWlw76XVlUN7ftV1RuG9g9U1VFTfTYM73F5VW1Y1p8GAAAA32Y5wfE3kryrqjZW1T8meWeS05bR76tJfmSYrXxIkhOr6hFJTk9yUXcfneSiYTtV9YAkJyV5YJITk7y8qvYZxnpFJiu8Hj08ThzaT0lyXXffN8lLkrxoGOuQJGckeXiSY5OcMR1QAQAAWL4dBsfuviiTsPYrw+P+3f2uZfTr7r5p2Nx3eHSSxyU5Z2g/J8njh9ePS/L67v5qd38myaYkx1bVYUkO7O73dXcnee02fbaO9aYkxw2zkSckubC7N3f3dUkuzDfDJgAAADthOauq3inJLyb5wUyC33uq6pXdfcsy+u6T5ENJ7pvkT7r7A1W1truvSZLuvqaq7jEcfniS9091v2pou3V4vW371j6fG8baUlXXJ7nbdPsSfabrOzWTmcysXbs2Gzdu3NFHYo5OO2bLvEtgB9bu7+9pkfmOg93nO26xOQ8tPueilWs5i+O8NsmNSV42bD8pyblJnrijjt19W5KHVNVdk7y5qh40cngtNcRI+672ma7vrCRnJcm6det6/fr1I+Uxbyef/tZ5l8AOnHbMlrz40uV8rTAPVzxl/bxLgBXPuWixOQ8tPueilWs5/2Xdf5tVVd+1s6uqdveXq2pjJpeLfr6qDhtmGw9Lcu1w2FVJjpzqdkSSq4f2I5Zon+5zVVWtSXJQks1D+/pt+mzcmZoBAACYWM7iOP88LGqTJKmqhyf53zvqVFV3H2YaU1X7J/nRJJ9MckGSraucbkhy/vD6giQnDSul3juT+yo/OFzWemNVPWK4f/Hp2/TZOtYTkrxzuA/y7UmOr6qDh0Vxjh/aAAAA2EnLmXF8eJKnV9WVw/Y9k3yiqi7NZA2c791Ov8OSnDPc53iHJOd191uq6n1JzquqU5JcmeGS1+6+rKrOS/LxJFuSPHu41DVJnpXkNUn2T/K24ZEkr0pyblVtymSm8aRhrM1V9YIkFw/HPb+7Ny/jswIAALCN5QTHXVqNtLv/T5LvW6L9S0mO206fM5OcuUT7JUm+7f7IYYGeJe+17O6zk5y9c1UDAACwrR0Gx+7+7J4oBAAAgMW0nHscAQAA2IsJjgAAAIwSHAEAABi1w+A4/AzGxVV1U1V9rapuq6ob9kRxAAAAzN9yZhz/OMmTklyeyc9hPDPJy2ZZFAAAAItjOT/Hke7eVFX7DL+r+Oqq+qcZ1wUAAMCCWE5w/I+qumOSj1TV7ye5JskBsy0LAACARbGcS1WfNhz3S0luTnJkkp+aZVEAAAAsjuUEx8d39y3dfUN3P6+7n5PksbMuDAAAgMWwnOC4YYm2k2/nOgAAAFhQ273HsaqelOTJSe5dVRdM7bpLki/NujAAAAAWw9jiOP+UyUI4hyZ58VT7jUn+zyyLAgAAYHFsNzh292eTfDbJD+y5cgAAAFg0O7zHsaoeUVUXV9VNVfW1qrqtqm7YE8UBAAAwf8tZHOePkzwpyeVJ9k/yzCQvm2VRAAAALI6xexy/obs3VdU+3X1bkldX1T/NuC4AAAAWxHKC439U1R2TfKSqfj+TBXMOmG1ZAAAALIrlXKr6tOG4X0pyc5Ijk/z0LIsCAABgcexwxrG7P1tVdx9eP2/2JQEAALBItjvjWBO/W1VfTPLJJP9SVV+oqt/Zc+UBAAAwb2OXqv5akkcm+f7uvlt3H5zk4UkeWVW/vieKAwAAYP7GguPTkzypuz+ztaG7P53kqcM+AAAA9gJjwXHf7v7ito3d/YUk+86uJAAAABbJWHD82i7uAwAAYBUZW1X1wVV1wxLtleROM6oHAACABbPd4Njd++zJQgAAAFhMY5eqAgAAgOAIAADAOMERAACAUYIjAAAAowRHAAAARgmOAAAAjBIcAQAAGCU4AgAAMEpwBAAAYJTgCAAAwCjBEQAAgFGCIwAAAKMERwAAAEYJjgAAAIwSHAEAABglOAIAADBKcAQAAGCU4AgAAMAowREAAIBRgiMAAACjZhYcq+rIqnpXVX2iqi6rql8d2g+pqgur6vLh+eCpPs+tqk1V9amqOmGq/WFVdemw76VVVUP7flX1hqH9A1V11FSfDcN7XF5VG2b1OQEAAFa7Wc44bklyWnd/T5JHJHl2VT0gyelJLuruo5NcNGxn2HdSkgcmOTHJy6tqn2GsVyQ5NcnRw+PEof2UJNd1932TvCTJi4axDklyRpKHJzk2yRnTARUAAIDlm1lw7O5ruvvDw+sbk3wiyeFJHpfknOGwc5I8fnj9uCSv7+6vdvdnkmxKcmxVHZbkwO5+X3d3ktdu02frWG9KctwwG3lCkgu7e3N3X5fkwnwzbAIAALAT1uyJNxkuIf2+JB9Isra7r0km4bKq7jEcdniS9091u2pou3V4vW371j6fG8baUlXXJ7nbdPsSfabrOjWTmcysXbs2Gzdu3OXPyOyddsyWeZfADqzd39/TIvMdB7vPd9xicx5afM5FK9fMg2NV3TnJXyf5te6+Ybg9cclDl2jrkfZd7fPNhu6zkpyVJOvWrev169dvrzYWwMmnv3XeJbADpx2zJS++dI/8exS74IqnrJ93CbDiORctNuehxedctHLNdFXVqto3k9D4l939N0Pz54fLTzM8Xzu0X5XkyKnuRyS5emg/Yon2b+lTVWuSHJRk88hYAAAA7KRZrqpaSV6V5BPd/QdTuy5IsnWV0w1Jzp9qP2lYKfXemSyC88HhstYbq+oRw5hP36bP1rGekOSdw32Qb09yfFUdPCyKc/zQBgAAwE6a5Vz+I5M8LcmlVfWRoe03k7wwyXlVdUqSK5M8MUm6+7KqOi/JxzNZkfXZ3X3b0O9ZSV6TZP8kbxseySSYnltVmzKZaTxpGGtzVb0gycXDcc/v7s0z+pwAAACr2syCY3e/N0vfa5gkx22nz5lJzlyi/ZIkD1qi/ZYMwXOJfWcnOXu59QIAALC0md7jCAAAwMonOAIAADBKcAQAAGCU4AgAAMAowREAAIBRgiMAAACjBEcAAABGCY4AAACMEhwBAAAYJTgCAAAwSnAEAABglOAIAADAKMERAACAUYIjAAAAowRHAAAARgmOAAAAjBIcAQAAGCU4AgAAMEpwBAAAYJTgCAAAwCjBEQAAgFGCIwAAAKMERwAAAEYJjgAAAIwSHAEAABglOAIAADBKcAQAAGCU4AgAAMAowREAAIBRgiMAAACjBEcAAABGCY4AAACMEhwBAAAYJTgCAAAwSnAEAABglOAIAADAKMERAACAUYIjAAAAowRHAAAARgmOAAAAjBIcAQAAGCU4AgAAMEpwBAAAYJTgCAAAwCjBEQAAgFGCIwAAAKMERwAAAEbNLDhW1dlVdW1VfWyq7ZCqurCqLh+eD57a99yq2lRVn6qqE6baH1ZVlw77XlpVNbTvV1VvGNo/UFVHTfXZMLzH5VW1YVafEQAAYG8wyxnH1yQ5cZu205Nc1N1HJ7lo2E5VPSDJSUkeOPR5eVXtM/R5RZJTkxw9PLaOeUqS67r7vklekuRFw1iHJDkjycOTHJvkjOmACgAAwM6ZWXDs7ncn2bxN8+OSnDO8PifJ46faX9/dX+3uzyTZlOTYqjosyYHd/b7u7iSv3abP1rHelOS4YTbyhCQXdvfm7r4uyYX59gALAADAMq3Zw++3truvSZLuvqaq7jG0H57k/VPHXTW03Tq83rZ9a5/PDWNtqarrk9xtun2JPt+iqk7NZDYza9euzcaNG3f5gzF7px2zZd4lsANr9/f3tMh8x8Hu8x232JyHFp9z0cq1p4Pj9tQSbT3Svqt9vrWx+6wkZyXJunXrev369TsslPk5+fS3zrsEduC0Y7bkxZcuytcK27riKevnXQKseM5Fi815aPE5F61ce3pV1c8Pl59meL52aL8qyZFTxx2R5Oqh/Ygl2r+lT1WtSXJQJpfGbm8sAAAAdsGeDo4XJNm6yumGJOdPtZ80rJR670wWwfngcFnrjVX1iOH+xadv02frWE9I8s7hPsi3Jzm+qg4eFsU5fmgDAABgF8xsLr+qXpdkfZJDq+qqTFY6fWGS86rqlCRXJnliknT3ZVV1XpKPJ9mS5Nndfdsw1LMyWaF1/yRvGx5J8qok51bVpkxmGk8axtpcVS9IcvFw3PO7e9tFegAAAFimmQXH7n7SdnYdt53jz0xy5hLtlyR50BLtt2QInkvsOzvJ2csuFgAAgO3a05eqAgAAsMIIjgAAAIwSHAEAABglOAIAADBKcAQAAGCU4AgAAMAowREAAIBRgiMAAACjBEcAAABGCY4AAACMEhwBAAAYJTgCAAAwSnAEAABglOAIAADAKMERAACAUYIjAAAAowRHAAAARgmOAAAAjBIcAQAAGCU4AgAAMEpwBAAAYJTgCAAAwCjBEQAAgFGCIwAAAKMERwAAAEYJjgAAAIwSHAEAABglOAIAADBKcAQAAGCU4AgAAMAowREAAIBRgiMAAACjBEcAAABGCY4AAACMEhwBAAAYJTgCAAAwSnAEAABglOAIAADAKMERAACAUYIjAAAAowRHAAAARgmOAAAAjBIcAQAAGCU4AgAAMEpwBAAAYJTgCAAAwCjBEQAAgFGrOjhW1YlV9amq2lRVp8+7HgAAgJVo1QbHqtonyZ8keXSSByR5UlU9YL5VAQAArDyrNjgmOTbJpu7+dHd/LcnrkzxuzjUBAACsONXd865hJqrqCUlO7O5nDttPS/Lw7v6lqWNOTXLqsHn/JJ/a44XC6nJoki/OuwgA9lrOQ7B77tXdd19qx5o9XckeVEu0fUtK7u6zkpy1Z8qB1a+qLunudfOuA4C9k/MQzM5qvlT1qiRHTm0fkeTqOdUCAACwYq3m4HhxkqOr6t5VdcckJyW5YM41AQAArDir9lLV7t5SVb+U5O1J9klydndfNueyYLVz6TcA8+Q8BDOyahfHAQAA4Paxmi9VBQAA4HYgOAIAADBKcAQAAGCU4AgAAMCoVbuqKjB7VfVdSa7q7q9W1fok35vktd395XnWBcDepar2SbI2U/9v291Xzq8iWH2sqgrssqr6SJJ1SY7K5KdvLkhy/+5+zBzLAmAvUlW/nOSMJJ9P8vWhubv7e+dXFaw+ZhyB3fH14TdTfzLJH3b3y6rqn+ddFAB7lV/N5B8tvzTvQmA1c48jsDturaonJdmQ5C1D275zrAeAvc/nklw/7yJgtTPjCOyOZyT5hSRndvdnqureSf5izjUBsHf5dJKNVfXWJF/d2tjdfzC/kmD1cY8jsFuq6o5J7jdsfqq7b51nPQDsXarqjKXau/t5e7oWWM0ER2CXDSupnpPkiiSV5MgkG7r73fOrCgCA25vgCOyyqvpQkid396eG7fsleV13P2y+lQGwt6iqv02y7f/QXp/kkiR/2t237PmqYPWxOA6wO/bdGhqTpLv/JRbHAWDP+nSSm5L82fC4IZOf5rjfsA3cDsw4Arusqs7O5F95zx2anpJkTXc/Y35VAbA3qap3d/cPL9VWVZd19wPnVRusJmYcgd3xrCSXJfmVTH5H6+OZrLIKAHvK3avqnls3hteHDptfm09JsPqYcQQAYMWqqsckeWWSf81kobZ7J/nFJBuT/Hx3/+HcioNVRHAEdlpVXZpvX4jgG7r7e/dgOQDs5apqvyTfnUlw/KQFceD2t2beBQAr0mOH52cPz9P3OP7Hni8HgL1NVf1Id7+zqn5qm133qap099/MpTBYpcw4Arusqv53dz9yR20AcHurqud19xlV9eoldnd3/9weLwpWMTOOwO44oKp+sLvfmyRV9cgkB8y5JgD2At19xvBsJW/YAwRHYHf8XJJXV9VBmdzzeH0SJ3AA9pjh/safTnJUpv7ftrufP6+aYDUSHIGdVlXPmdp8bSazjDcP249K8s97vCgA9lbnZ/IPlx9K8tU51wKrluAI7Iq7DM/3T/L9mZy0D0ryE0nePa+iANgrHdHdJ867CFjtLI4D7LKqekeSn+7uG4ftuyR5oxM4AHtKVZ2V5GXdfem8a4HVzIwjsDvumeRrU9tfy+QeEwDYU34wyclV9ZlMLlWtTFZV9ZvCcDsSHIHdcW6SD1bVmzNZHOcnk5wz35IA2Ms8et4FwN7AparAbqmqhyb5oWHz3d1tYRwA9qiq+sEkR3f3q6vq7knu3N2fmXddsJoIjgAArFhVdUaSdUnu3933q6rvzOR++0fOuTRYVe4w7wIAAGA3/GSS/5rhZ6G6++p8c/Vv4HYiOAIAsJJ9rSeX0HWSVNUBc64HViXBEQCAley8qvrTJHetqp9P8g9J/mzONcGq4x5HAABWtKr6sSTHZ/JTHG/v7gvnXBKsOoIjAACrQlUdmuRL7X9w4XbnUlUAAFacqnpEVW2sqr+pqu+rqo8l+ViSz1fVifOuD1YbM44AAKw4VXVJkt9MclCSs5I8urvfX1XfneR13f19cy0QVhkzjgAArERruvsd3f3GJP/e3e9Pku7+5JzrglVJcAQAYCX6+tTrr2yzzyV1cDtzqSoAACtOVd2W5OZMVlLdP8l/bN2V5E7dve+8aoPVSHAEAABglEtVAQAAGCU4AgAAMEpwBIAZqar/VFWvr6p/raqPV9XfVdX9ht+bA4AVY828CwCA1aiqKsmbk5zT3ScNbQ9JsnaedQHArjDjCACz8agkt3b3K7c2dPdHknxu63ZVHVVV76mqDw+P/zy0H1ZV766qj1TVx6rqh6pqn6p6zbB9aVX9+h7/RADstcw4AsBsPCjJh3ZwzLVJfqy7b6mqo5O8Lsm6JE9O8vbuPrOq9knyHUkekuTw7n5QklTVXWdVOABsS3AEgPnZN8kfD5ew3pbkfkP7xUnOrqp9k/x/3f2Rqvp0kvtU1cuSvDXJO+ZRMAB7J5eqAsBsXJbkYTs45teTfD7JgzOZabxjknT3u5P8cJJ/S3JuVT29u68bjtuY5NlJ/nw2ZQPAtxMcAWA23plkv6r6+a0NVfX9Se41dcxBSa7p7q8neVqSfYbj7pXk2u7+sySvSvLQqjo0yR26+6+T/HaSh+6ZjwEALlUFgJno7q6qn0zyh1V1epJbklyR5NemDnt5kr+uqicmeVeSm4f29Ul+o6puTXJTkqcnOTzJq6tq6z/6PnfWnwEAtqrunncNAAAALDCXqgIAADBKcAQAAGCU4AgAAMAowREAAIBRgiMAAACjBEcAAABGCY4AAACM+v8BestBo74RQFMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Exploratory data analysis\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import *\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "class_distribution = df['Label'].value_counts()\n",
    "class_distribution.plot(kind='bar')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Data points per Class')\n",
    "plt.title('Distribution of Data')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6f8b857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting unique values and checking for skewness in the data\n",
    "rowbuilder = lambda col: {'col': col, 'unique_values': df[col].nunique(), 'most_frequent_value': df[col].value_counts().index[0],'frequency': df[col].value_counts(normalize=True).values[0]}\n",
    "frequency = [rowbuilder(col) for col in df.select_dtypes(include=['category']).columns]\n",
    "skewed = pd.DataFrame(frequency)\n",
    "skewed = skewed[skewed['frequency'] >= 0.95]\n",
    "colsToDrop = np.union1d(colsToDrop, skewed['col'].values)\n",
    "colsToDrop\n",
    "del skewed\n",
    "del rowbuilder\n",
    "del frequency\n",
    "\n",
    "missing = df.isna().sum()\n",
    "missing = pd.DataFrame({'count': missing, '% of total': missing/len(df)*100}, index=df.columns)\n",
    "colsToDrop = np.union1d(colsToDrop, missing[missing['% of total'] >= 50].index.values)\n",
    "dropnaCols = missing[(missing['% of total'] > 0) & (missing['% of total'] <= 5)].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93c75577",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Flow Byts/s'].replace(np.inf, np.nan, inplace=True)\n",
    "df['Flow Pkts/s'].replace(np.inf, np.nan, inplace=True)\n",
    "dropnaCols = np.union1d(dropnaCols, ['Flow Byts/s', 'Flow Pkts/s'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "332f1360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping some columns: \n",
      "\t there are 68 columns and 1273270 rows\n"
     ]
    }
   ],
   "source": [
    "# perform actual drop\n",
    "df.drop(columns=colsToDrop, inplace=True)\n",
    "df.dropna(subset=dropnaCols, inplace=True)\n",
    "\n",
    "print('After dropping some columns: \\n\\t there are {} columns and {} rows'.format(len(df.columns), len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b4df76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "negValCols = ['Flow Pkts/s', 'Flow IAT Mean', 'Flow IAT Max', 'Flow IAT Min', 'Bwd IAT Tot', 'Bwd IAT Mean', 'Bwd IAT Max', 'Bwd IAT Min']\n",
    "for col in negValCols:\n",
    "    df = df[df[col] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f55d87d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Src Port</th>\n",
       "      <th>Dst Port</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Tot Fwd Pkts</th>\n",
       "      <th>Tot Bwd Pkts</th>\n",
       "      <th>TotLen Fwd Pkts</th>\n",
       "      <th>TotLen Bwd Pkts</th>\n",
       "      <th>Fwd Pkt Len Max</th>\n",
       "      <th>Fwd Pkt Len Min</th>\n",
       "      <th>Fwd Pkt Len Mean</th>\n",
       "      <th>...</th>\n",
       "      <th>Fwd Act Data Pkts</th>\n",
       "      <th>Fwd Seg Size Min</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.273224e+06</td>\n",
       "      <td>1.273224e+06</td>\n",
       "      <td>1.273224e+06</td>\n",
       "      <td>1.273224e+06</td>\n",
       "      <td>1.273224e+06</td>\n",
       "      <td>1.273224e+06</td>\n",
       "      <td>1.273224e+06</td>\n",
       "      <td>1.273224e+06</td>\n",
       "      <td>1.273224e+06</td>\n",
       "      <td>1.273224e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.273224e+06</td>\n",
       "      <td>1.273224e+06</td>\n",
       "      <td>1.273224e+06</td>\n",
       "      <td>1.273224e+06</td>\n",
       "      <td>1.273224e+06</td>\n",
       "      <td>1.273224e+06</td>\n",
       "      <td>1.273224e+06</td>\n",
       "      <td>1.273224e+06</td>\n",
       "      <td>1.273224e+06</td>\n",
       "      <td>1.273224e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.723088e+04</td>\n",
       "      <td>1.450845e+04</td>\n",
       "      <td>8.210078e+06</td>\n",
       "      <td>2.313363e+01</td>\n",
       "      <td>4.842093e+00</td>\n",
       "      <td>1.002113e+03</td>\n",
       "      <td>2.875697e+03</td>\n",
       "      <td>2.915275e+02</td>\n",
       "      <td>7.130953e+00</td>\n",
       "      <td>7.623763e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.023237e+01</td>\n",
       "      <td>8.070718e+00</td>\n",
       "      <td>1.380251e+05</td>\n",
       "      <td>6.912317e+04</td>\n",
       "      <td>2.059417e+05</td>\n",
       "      <td>9.156066e+04</td>\n",
       "      <td>3.125685e+06</td>\n",
       "      <td>1.082937e+05</td>\n",
       "      <td>3.220184e+06</td>\n",
       "      <td>3.025588e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.516909e+04</td>\n",
       "      <td>2.299897e+04</td>\n",
       "      <td>2.474097e+07</td>\n",
       "      <td>1.540472e+03</td>\n",
       "      <td>1.168300e+02</td>\n",
       "      <td>4.928998e+04</td>\n",
       "      <td>1.681727e+05</td>\n",
       "      <td>3.936677e+02</td>\n",
       "      <td>1.972144e+01</td>\n",
       "      <td>9.425118e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.539942e+03</td>\n",
       "      <td>9.124339e+00</td>\n",
       "      <td>2.312038e+06</td>\n",
       "      <td>1.397170e+06</td>\n",
       "      <td>3.057354e+06</td>\n",
       "      <td>1.950657e+06</td>\n",
       "      <td>1.221854e+07</td>\n",
       "      <td>1.398069e+06</td>\n",
       "      <td>1.247329e+07</td>\n",
       "      <td>1.210786e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.430000e+02</td>\n",
       "      <td>8.000000e+01</td>\n",
       "      <td>1.279000e+03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.062700e+04</td>\n",
       "      <td>8.000000e+01</td>\n",
       "      <td>3.249400e+04</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.200000e+01</td>\n",
       "      <td>1.150000e+02</td>\n",
       "      <td>4.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.600000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.627200e+04</td>\n",
       "      <td>3.797600e+04</td>\n",
       "      <td>4.164903e+06</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>9.350000e+02</td>\n",
       "      <td>3.580000e+02</td>\n",
       "      <td>6.770000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.430000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.553500e+04</td>\n",
       "      <td>6.553400e+04</td>\n",
       "      <td>1.200000e+08</td>\n",
       "      <td>2.373490e+05</td>\n",
       "      <td>2.758900e+04</td>\n",
       "      <td>7.595168e+06</td>\n",
       "      <td>3.802143e+07</td>\n",
       "      <td>1.606000e+04</td>\n",
       "      <td>1.472000e+03</td>\n",
       "      <td>2.025714e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>2.373490e+05</td>\n",
       "      <td>4.400000e+01</td>\n",
       "      <td>1.112835e+08</td>\n",
       "      <td>6.879098e+07</td>\n",
       "      <td>1.112835e+08</td>\n",
       "      <td>1.112835e+08</td>\n",
       "      <td>1.199882e+08</td>\n",
       "      <td>7.599266e+07</td>\n",
       "      <td>1.199882e+08</td>\n",
       "      <td>1.199882e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Src Port      Dst Port  Flow Duration  Tot Fwd Pkts  Tot Bwd Pkts  \\\n",
       "count  1.273224e+06  1.273224e+06   1.273224e+06  1.273224e+06  1.273224e+06   \n",
       "mean   3.723088e+04  1.450845e+04   8.210078e+06  2.313363e+01  4.842093e+00   \n",
       "std    2.516909e+04  2.299897e+04   2.474097e+07  1.540472e+03  1.168300e+02   \n",
       "min    0.000000e+00  0.000000e+00   1.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    4.430000e+02  8.000000e+01   1.279000e+03  1.000000e+00  1.000000e+00   \n",
       "50%    5.062700e+04  8.000000e+01   3.249400e+04  2.000000e+00  1.000000e+00   \n",
       "75%    5.627200e+04  3.797600e+04   4.164903e+06  4.000000e+00  4.000000e+00   \n",
       "max    6.553500e+04  6.553400e+04   1.200000e+08  2.373490e+05  2.758900e+04   \n",
       "\n",
       "       TotLen Fwd Pkts  TotLen Bwd Pkts  Fwd Pkt Len Max  Fwd Pkt Len Min  \\\n",
       "count     1.273224e+06     1.273224e+06     1.273224e+06     1.273224e+06   \n",
       "mean      1.002113e+03     2.875697e+03     2.915275e+02     7.130953e+00   \n",
       "std       4.928998e+04     1.681727e+05     3.936677e+02     1.972144e+01   \n",
       "min       0.000000e+00     0.000000e+00     0.000000e+00     0.000000e+00   \n",
       "25%       0.000000e+00     0.000000e+00     0.000000e+00     0.000000e+00   \n",
       "50%       4.200000e+01     1.150000e+02     4.000000e+01     0.000000e+00   \n",
       "75%       9.350000e+02     3.580000e+02     6.770000e+02     0.000000e+00   \n",
       "max       7.595168e+06     3.802143e+07     1.606000e+04     1.472000e+03   \n",
       "\n",
       "       Fwd Pkt Len Mean  ...  Fwd Act Data Pkts  Fwd Seg Size Min  \\\n",
       "count      1.273224e+06  ...       1.273224e+06      1.273224e+06   \n",
       "mean       7.623763e+01  ...       2.023237e+01      8.070718e+00   \n",
       "std        9.425118e+01  ...       1.539942e+03      9.124339e+00   \n",
       "min        0.000000e+00  ...       0.000000e+00      0.000000e+00   \n",
       "25%        0.000000e+00  ...       0.000000e+00      0.000000e+00   \n",
       "50%        3.600000e+01  ...       0.000000e+00      0.000000e+00   \n",
       "75%        1.430000e+02  ...       1.000000e+00      2.000000e+01   \n",
       "max        2.025714e+03  ...       2.373490e+05      4.400000e+01   \n",
       "\n",
       "        Active Mean    Active Std    Active Max    Active Min     Idle Mean  \\\n",
       "count  1.273224e+06  1.273224e+06  1.273224e+06  1.273224e+06  1.273224e+06   \n",
       "mean   1.380251e+05  6.912317e+04  2.059417e+05  9.156066e+04  3.125685e+06   \n",
       "std    2.312038e+06  1.397170e+06  3.057354e+06  1.950657e+06  1.221854e+07   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "max    1.112835e+08  6.879098e+07  1.112835e+08  1.112835e+08  1.199882e+08   \n",
       "\n",
       "           Idle Std      Idle Max      Idle Min  \n",
       "count  1.273224e+06  1.273224e+06  1.273224e+06  \n",
       "mean   1.082937e+05  3.220184e+06  3.025588e+06  \n",
       "std    1.398069e+06  1.247329e+07  1.210786e+07  \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "25%    0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "50%    0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "75%    0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "max    7.599266e+07  1.199882e+08  1.199882e+08  \n",
       "\n",
       "[8 rows x 60 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a84b656e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1273224, 68)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dcfe21ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    646389\n",
       "0    626835\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "\n",
    "\n",
    "#drop na values and reset index\n",
    "data_clean = df.dropna().reset_index()\n",
    "\n",
    "# label encoding\n",
    "labelencoder = LabelEncoder()\n",
    "data_clean['Label'] = labelencoder.fit_transform(data_clean['Label'])\n",
    "\n",
    "data_clean['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ffa3108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1273224, 69)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "febec40f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'Src Port', 'Dst Port', 'Protocol', 'Flow Duration',\n",
       "       'Tot Fwd Pkts', 'Tot Bwd Pkts', 'TotLen Fwd Pkts', 'TotLen Bwd Pkts',\n",
       "       'Fwd Pkt Len Max', 'Fwd Pkt Len Min', 'Fwd Pkt Len Mean',\n",
       "       'Fwd Pkt Len Std', 'Bwd Pkt Len Max', 'Bwd Pkt Len Min',\n",
       "       'Bwd Pkt Len Mean', 'Bwd Pkt Len Std', 'Flow Byts/s', 'Flow Pkts/s',\n",
       "       'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min',\n",
       "       'Fwd IAT Tot', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max',\n",
       "       'Fwd IAT Min', 'Bwd IAT Tot', 'Bwd IAT Mean', 'Bwd IAT Std',\n",
       "       'Bwd IAT Max', 'Bwd IAT Min', 'Fwd Header Len', 'Bwd Header Len',\n",
       "       'Fwd Pkts/s', 'Bwd Pkts/s', 'Pkt Len Min', 'Pkt Len Max',\n",
       "       'Pkt Len Mean', 'Pkt Len Std', 'Pkt Len Var', 'SYN Flag Cnt',\n",
       "       'RST Flag Cnt', 'PSH Flag Cnt', 'ACK Flag Cnt', 'CWE Flag Count',\n",
       "       'ECE Flag Cnt', 'Down/Up Ratio', 'Pkt Size Avg', 'Fwd Seg Size Avg',\n",
       "       'Bwd Seg Size Avg', 'Subflow Fwd Pkts', 'Subflow Fwd Byts',\n",
       "       'Subflow Bwd Pkts', 'Subflow Bwd Byts', 'Init Fwd Win Byts',\n",
       "       'Init Bwd Win Byts', 'Fwd Act Data Pkts', 'Fwd Seg Size Min',\n",
       "       'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean',\n",
       "       'Idle Std', 'Idle Max', 'Idle Min', 'Label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41c8695c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Src Port</th>\n",
       "      <th>Dst Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Tot Fwd Pkts</th>\n",
       "      <th>Tot Bwd Pkts</th>\n",
       "      <th>TotLen Fwd Pkts</th>\n",
       "      <th>TotLen Bwd Pkts</th>\n",
       "      <th>Fwd Pkt Len Max</th>\n",
       "      <th>...</th>\n",
       "      <th>Fwd Seg Size Min</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4529</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>135</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4533</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4541</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>478574</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>92.0</td>\n",
       "      <td>958.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4543</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>1242607</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>105.0</td>\n",
       "      <td>20702.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1722</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>1859292</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Src Port  Dst Port Protocol  Flow Duration  Tot Fwd Pkts  \\\n",
       "0      0      4529        80        6            135             1   \n",
       "1      1      4533        80        6             91             1   \n",
       "2      2      4541        80        6         478574             2   \n",
       "3      3      4543        80        6        1242607             9   \n",
       "4      4      1722        80        6        1859292             1   \n",
       "\n",
       "   Tot Bwd Pkts  TotLen Fwd Pkts  TotLen Bwd Pkts  Fwd Pkt Len Max  ...  \\\n",
       "0             1              0.0              0.0              0.0  ...   \n",
       "1             1              0.0              0.0              0.0  ...   \n",
       "2             5             92.0            958.0             92.0  ...   \n",
       "3            19            105.0          20702.0            105.0  ...   \n",
       "4             1              0.0              0.0              0.0  ...   \n",
       "\n",
       "   Fwd Seg Size Min  Active Mean  Active Std  Active Max  Active Min  \\\n",
       "0                 0          0.0         0.0         0.0         0.0   \n",
       "1                 0          0.0         0.0         0.0         0.0   \n",
       "2                 0          0.0         0.0         0.0         0.0   \n",
       "3                 0          0.0         0.0         0.0         0.0   \n",
       "4                 0          0.0         0.0         0.0         0.0   \n",
       "\n",
       "   Idle Mean  Idle Std  Idle Max  Idle Min  Label  \n",
       "0        0.0       0.0       0.0       0.0      1  \n",
       "1        0.0       0.0       0.0       0.0      1  \n",
       "2        0.0       0.0       0.0       0.0      1  \n",
       "3        0.0       0.0       0.0       0.0      1  \n",
       "4        0.0       0.0       0.0       0.0      1  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf35661b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_np = data_clean.to_numpy(dtype=\"float32\")\n",
    "data_np = data_np[~np.isinf(data_np).any(axis=1)]\n",
    "\n",
    "#del df\n",
    "\n",
    "X = data_np[:, 0:67]\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "\n",
    "Y = enc.fit_transform(data_np[:,68:]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c5dc0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data set into training and testing\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X_scaled, Y, test_size=0.25, random_state=2, shuffle=True)\n",
    "\n",
    "_features = X.shape[1]\n",
    "n_classes = Y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3b6cb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(954918, 67)\n",
      "(954918, 2)\n",
      "(318306, 67)\n",
      "(318306, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "73df92c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1273224, 67)\n",
      "(1273224, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9642a2de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1cf471fa",
   "metadata": {},
   "source": [
    "# DNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7f32bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to ignore FutureWarning\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras import callbacks\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d30f72aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                4352      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 78,856\n",
      "Trainable params: 78,856\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "7461/7461 [==============================] - 25s 3ms/step - loss: 0.0182 - accuracy: 0.9955 - val_loss: 4.9942e-04 - val_accuracy: 0.9999\n",
      "Epoch 2/30\n",
      "7461/7461 [==============================] - 23s 3ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 3.8328e-04 - val_accuracy: 0.9999\n",
      "Epoch 3/30\n",
      "7461/7461 [==============================] - 24s 3ms/step - loss: 5.7707e-04 - accuracy: 0.9999 - val_loss: 3.4704e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "7461/7461 [==============================] - 23s 3ms/step - loss: 4.6127e-04 - accuracy: 0.9999 - val_loss: 2.3850e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "7461/7461 [==============================] - 23s 3ms/step - loss: 2.7675e-04 - accuracy: 0.9999 - val_loss: 2.0829e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "7461/7461 [==============================] - 23s 3ms/step - loss: 3.6022e-04 - accuracy: 1.0000 - val_loss: 3.7392e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "7461/7461 [==============================] - 24s 3ms/step - loss: 2.4061e-04 - accuracy: 1.0000 - val_loss: 2.4507e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "7461/7461 [==============================] - 23s 3ms/step - loss: 2.0769e-04 - accuracy: 1.0000 - val_loss: 2.8859e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "7461/7461 [==============================] - 23s 3ms/step - loss: 1.6454e-04 - accuracy: 1.0000 - val_loss: 3.1289e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "7461/7461 [==============================] - 23s 3ms/step - loss: 2.4031e-04 - accuracy: 1.0000 - val_loss: 3.7419e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "7461/7461 [==============================] - 23s 3ms/step - loss: 2.4533e-04 - accuracy: 1.0000 - val_loss: 4.3344e-04 - val_accuracy: 0.9999\n",
      "Epoch 12/30\n",
      "7461/7461 [==============================] - 23s 3ms/step - loss: 1.5176e-04 - accuracy: 1.0000 - val_loss: 2.4041e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "7461/7461 [==============================] - 23s 3ms/step - loss: 8.4393e-05 - accuracy: 1.0000 - val_loss: 2.2443e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "7461/7461 [==============================] - 23s 3ms/step - loss: 1.2133e-04 - accuracy: 1.0000 - val_loss: 2.4896e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "7461/7461 [==============================] - 24s 3ms/step - loss: 1.5498e-04 - accuracy: 1.0000 - val_loss: 2.4795e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "7461/7461 [==============================] - 23s 3ms/step - loss: 1.5273e-04 - accuracy: 1.0000 - val_loss: 2.9848e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "7461/7461 [==============================] - 23s 3ms/step - loss: 1.7825e-04 - accuracy: 1.0000 - val_loss: 3.9242e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "7461/7461 [==============================] - 23s 3ms/step - loss: 8.4976e-05 - accuracy: 1.0000 - val_loss: 4.5720e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "7461/7461 [==============================] - 23s 3ms/step - loss: 1.0263e-04 - accuracy: 1.0000 - val_loss: 3.6187e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "7461/7461 [==============================] - 23s 3ms/step - loss: 1.2639e-04 - accuracy: 1.0000 - val_loss: 3.1301e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "7461/7461 [==============================] - 23s 3ms/step - loss: 7.4207e-05 - accuracy: 1.0000 - val_loss: 3.8760e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "7461/7461 [==============================] - 23s 3ms/step - loss: 1.1488e-04 - accuracy: 1.0000 - val_loss: 3.5507e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "7461/7461 [==============================] - 23s 3ms/step - loss: 6.3718e-05 - accuracy: 1.0000 - val_loss: 4.5475e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "7461/7461 [==============================] - 23s 3ms/step - loss: 5.5314e-05 - accuracy: 1.0000 - val_loss: 5.9815e-04 - val_accuracy: 0.9999\n",
      "Epoch 25/30\n",
      "7461/7461 [==============================] - 23s 3ms/step - loss: 8.2157e-05 - accuracy: 1.0000 - val_loss: 5.5154e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "7461/7461 [==============================] - 23s 3ms/step - loss: 7.9645e-05 - accuracy: 1.0000 - val_loss: 5.1519e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "7461/7461 [==============================] - 23s 3ms/step - loss: 1.0106e-04 - accuracy: 1.0000 - val_loss: 6.2350e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "7461/7461 [==============================] - 23s 3ms/step - loss: 1.0263e-04 - accuracy: 1.0000 - val_loss: 3.8779e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "7461/7461 [==============================] - 23s 3ms/step - loss: 1.3822e-04 - accuracy: 1.0000 - val_loss: 3.7002e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "7461/7461 [==============================] - 23s 3ms/step - loss: 9.7667e-05 - accuracy: 1.0000 - val_loss: 3.8029e-04 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Simple 3 Layer Dense Model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(64, input_dim=_features, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(n_classes, kernel_initializer='normal'))\n",
    "model.add(Dense(n_classes, activation = 'softmax'))\n",
    "\n",
    "model.summary() \n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(loss='BinaryCrossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                                  patience=3, min_lr=0.0001)\n",
    "    \n",
    "history = model.fit(X_train, Y_train,\n",
    "                              batch_size=128,\n",
    "                              epochs=30,\n",
    "                              verbose=True,\n",
    "                              validation_data=(X_test, Y_test))\n",
    "                              #callbacks=[reduce_lr, early_stop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "76407e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('H:/Datasets/kaggle_ddos/dnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a93b945f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9948/9948 [==============================] - 8s 825us/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "y_test = Y_test.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72d2d793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318306,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5289b32f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[156525,      5],\n",
       "       [     4, 161772]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "import seaborn as sn\n",
    "\n",
    "confMat = confusion_matrix(y_test, pred)\n",
    "confMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06352f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(y_test, pred)\n",
    "\n",
    "labels = ['ddos', 'benign']\n",
    "\n",
    "sn.heatmap(cf_matrix / np.sum(cf_matrix), annot=True, fmt='.2%', xticklabels=labels, yticklabels=labels, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bc6be540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9948/9948 [==============================] - 15s 2ms/step - loss: 3.8026e-04 - accuracy: 1.0000\n",
      "9948/9948 [==============================] - 9s 855us/step\n",
      "Inference time: 11.28 seconds\n",
      "Completed\n",
      "Time taken: 0:00:26.718039\n",
      "Validation score: 0.9999717253209176\n",
      "Evaluation score: [0.00038026354741305113, 0.9999717473983765]\n",
      "Recall score: 0.9999717253209176\n",
      "Precision score: 0.9999717253377328\n",
      "F1 Measure score: 0.9999717253194529\n",
      "ROC-AUC score: 0.9999716658474943\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn import preprocessing\n",
    "import time\n",
    "\n",
    "start = dt.datetime.now()\n",
    "\n",
    "escore = model.evaluate(X_test, Y_test, batch_size=32)\n",
    "\n",
    "# Measure inference time\n",
    "start_time = time.time()\n",
    "pred = model.predict(X_test)\n",
    "end_time = time.time()\n",
    "\n",
    "inference_time = end_time - start_time\n",
    "print(\"Inference time: {:.2f} seconds\".format(inference_time))\n",
    "\n",
    "pred = np.argmax(pred,axis=1)\n",
    "y_eval = np.argmax(Y_test,axis=1)\n",
    "\n",
    "score = metrics.accuracy_score(y_eval, pred)\n",
    "rscore = recall_score(y_eval, pred, average='weighted')\n",
    "ascore = precision_score(y_eval, pred, average='weighted')\n",
    "f1score= f1_score(y_eval, pred, average='weighted') #F1 = 2 * (precision * recall) / (precision + recall) for manual\n",
    "\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(y_eval)\n",
    "y_eval = lb.transform(y_eval)\n",
    "pred = lb.transform(pred)\n",
    "roc_score = roc_auc_score(y_eval, pred)\n",
    "\n",
    "print('Completed')\n",
    "print('Time taken:',dt.datetime.now()-start)\n",
    "\n",
    "print(\"Validation score: {}\".format(score))\n",
    "print(\"Evaluation score: {}\".format(escore))\n",
    "print(\"Recall score: {}\".format(rscore))\n",
    "print(\"Precision score: {}\".format(ascore))\n",
    "print(\"F1 Measure score: {}\".format(f1score))\n",
    "print(\"ROC-AUC score: {}\".format(roc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6ba32752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for training and validation loss\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "caf7c333",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_by_epoch = 1\n",
    "epochs = range(start_by_epoch, len(loss_values) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6389537c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, acc[start_by_epoch-1:], label='Training accuracy')\n",
    "plt.plot(epochs, val_acc[start_by_epoch-1:], label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Training', 'Validation'], loc='lower right')\n",
    "\n",
    "plt.show()\n",
    "plt.clf()\n",
    "\n",
    "\n",
    "#plt.subplot(212)\n",
    "\n",
    "plt.plot(epochs, loss_values[start_by_epoch-1:], label='Training Loss')\n",
    "plt.plot(epochs, val_loss_values[start_by_epoch-1:], label='Validation Loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Training', 'Validation'], loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ef0e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1.2)\n",
    "plt.title('Training and Validation Rate')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f2aa1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "638087f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ba020d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9dbc696",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6ee93741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 67, 128)           896       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 33, 128)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 33, 256)           196864    \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 16, 256)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               1048832   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 2)                 514       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 2)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,247,112\n",
      "Trainable params: 1,247,112\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "7461/7461 [==============================] - 30s 4ms/step - loss: 0.0073 - accuracy: 0.9985 - val_loss: 3.8639e-04 - val_accuracy: 0.9999\n",
      "Epoch 2/30\n",
      "7461/7461 [==============================] - 28s 4ms/step - loss: 7.2855e-04 - accuracy: 0.9999 - val_loss: 1.4032e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "7461/7461 [==============================] - 27s 4ms/step - loss: 7.3773e-04 - accuracy: 0.9999 - val_loss: 2.3299e-04 - val_accuracy: 0.9999\n",
      "Epoch 4/30\n",
      "7461/7461 [==============================] - 28s 4ms/step - loss: 3.6986e-04 - accuracy: 0.9999 - val_loss: 8.4300e-04 - val_accuracy: 0.9998\n",
      "Epoch 5/30\n",
      "7461/7461 [==============================] - 28s 4ms/step - loss: 4.0465e-04 - accuracy: 0.9999 - val_loss: 1.2983e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "7461/7461 [==============================] - 27s 4ms/step - loss: 2.7770e-04 - accuracy: 0.9999 - val_loss: 3.0712e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "7461/7461 [==============================] - 27s 4ms/step - loss: 2.5365e-04 - accuracy: 1.0000 - val_loss: 4.0813e-04 - val_accuracy: 0.9999\n",
      "Epoch 8/30\n",
      "7461/7461 [==============================] - 27s 4ms/step - loss: 2.3287e-04 - accuracy: 1.0000 - val_loss: 3.4885e-04 - val_accuracy: 0.9999\n",
      "Epoch 9/30\n",
      "7461/7461 [==============================] - 27s 4ms/step - loss: 2.0260e-04 - accuracy: 1.0000 - val_loss: 1.4808e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "7461/7461 [==============================] - 27s 4ms/step - loss: 1.5733e-04 - accuracy: 1.0000 - val_loss: 1.2820e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "7461/7461 [==============================] - 27s 4ms/step - loss: 1.5847e-04 - accuracy: 1.0000 - val_loss: 2.1966e-04 - val_accuracy: 0.9999\n",
      "Epoch 12/30\n",
      "7461/7461 [==============================] - 27s 4ms/step - loss: 2.6576e-04 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9998\n",
      "Epoch 13/30\n",
      "7461/7461 [==============================] - 28s 4ms/step - loss: 4.9125e-04 - accuracy: 1.0000 - val_loss: 1.2822e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "7461/7461 [==============================] - 28s 4ms/step - loss: 1.4367e-04 - accuracy: 1.0000 - val_loss: 9.4927e-05 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "7461/7461 [==============================] - 27s 4ms/step - loss: 1.7250e-04 - accuracy: 1.0000 - val_loss: 1.2087e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "7461/7461 [==============================] - 27s 4ms/step - loss: 1.4656e-04 - accuracy: 1.0000 - val_loss: 1.3306e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "7461/7461 [==============================] - 27s 4ms/step - loss: 1.7707e-04 - accuracy: 1.0000 - val_loss: 9.4242e-05 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "7461/7461 [==============================] - 27s 4ms/step - loss: 1.7494e-04 - accuracy: 1.0000 - val_loss: 7.5396e-05 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "7461/7461 [==============================] - 28s 4ms/step - loss: 9.4294e-05 - accuracy: 1.0000 - val_loss: 1.0303e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "7461/7461 [==============================] - 28s 4ms/step - loss: 7.2761e-05 - accuracy: 1.0000 - val_loss: 8.2209e-05 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "7461/7461 [==============================] - 27s 4ms/step - loss: 2.0266e-04 - accuracy: 1.0000 - val_loss: 1.4421e-04 - val_accuracy: 0.9999\n",
      "Epoch 22/30\n",
      "7461/7461 [==============================] - 27s 4ms/step - loss: 1.4270e-04 - accuracy: 1.0000 - val_loss: 8.7810e-05 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "7461/7461 [==============================] - 27s 4ms/step - loss: 1.1821e-04 - accuracy: 1.0000 - val_loss: 1.5593e-04 - val_accuracy: 0.9999\n",
      "Epoch 24/30\n",
      "7461/7461 [==============================] - 27s 4ms/step - loss: 2.0117e-04 - accuracy: 1.0000 - val_loss: 9.6454e-05 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "7461/7461 [==============================] - 28s 4ms/step - loss: 6.6333e-05 - accuracy: 1.0000 - val_loss: 1.4764e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "7461/7461 [==============================] - 27s 4ms/step - loss: 1.3348e-04 - accuracy: 1.0000 - val_loss: 1.3717e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "7461/7461 [==============================] - 27s 4ms/step - loss: 9.3126e-05 - accuracy: 1.0000 - val_loss: 7.2598e-04 - val_accuracy: 0.9998\n",
      "Epoch 28/30\n",
      "7461/7461 [==============================] - 27s 4ms/step - loss: 1.0146e-04 - accuracy: 1.0000 - val_loss: 5.7186e-05 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "7461/7461 [==============================] - 27s 4ms/step - loss: 8.2562e-05 - accuracy: 1.0000 - val_loss: 6.3312e-05 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "7461/7461 [==============================] - 27s 4ms/step - loss: 1.2134e-04 - accuracy: 1.0000 - val_loss: 5.1810e-05 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# In order to ignore FutureWarning\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras import callbacks\n",
    "from keras.layers import Dense, Activation, Flatten, Convolution1D, MaxPooling1D, Dropout\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 67, 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 67, 1).astype('float32')\n",
    "\n",
    "\n",
    "# CNN Model\n",
    "model = Sequential()\n",
    "model.add(Convolution1D(filters=128, kernel_size=6, padding=\"same\", activation=\"relu\", input_shape=(_features, 1)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Convolution1D(filters=256, kernel_size=6, padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(n_classes, kernel_initializer='normal'))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model.summary() \n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "early_stop_callback = keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                                  patience=3, min_lr=0.001)\n",
    "    \n",
    "history = model.fit(X_train, Y_train,\n",
    "                              batch_size=128,\n",
    "                              epochs=30,\n",
    "                              verbose=True,\n",
    "                              validation_data=(X_test, Y_test))\n",
    "                              #callbacks=[reduce_lr, early_stop_callback]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4d43c771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9948/9948 [==============================] - 9s 943us/step\n",
      "Best loss: 5.181006054044701e-05\n",
      "Balanced Acc loss: 99.99779508166564\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(model.predict(X_test), axis=-1)\n",
    "balanced_score = metrics.balanced_accuracy_score(np.argmax(Y_test, axis=1), y_pred) * 100\n",
    "    \n",
    "best_loss = np.amin(history.history['val_loss']) \n",
    "print('Best loss: {}'.format(best_loss))\n",
    "print('Balanced Acc loss: {}'.format(balanced_score))\n",
    "\n",
    "\n",
    "#model.save('H:/Datasets/kaggle_ddos/balance_cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "93f827fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for training and validation loss\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6f3a1b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9948/9948 [==============================] - 9s 951us/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "y_test = Y_test.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1d2990b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318306,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4f313848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[156526,      4],\n",
       "       [     3, 161773]], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "import seaborn as sn\n",
    "\n",
    "confMat = confusion_matrix(y_test, pred)\n",
    "confMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3078da7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(y_test, pred)\n",
    "\n",
    "labels = ['DDoS', 'Benign']\n",
    "\n",
    "sn.heatmap(cf_matrix / np.sum(cf_matrix), annot=True, fmt='.2%', xticklabels=labels, yticklabels=labels, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "865de3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9948/9948 [==============================] - 17s 2ms/step - loss: 5.1814e-05 - accuracy: 1.0000\n",
      "9948/9948 [==============================] - 9s 920us/step\n",
      "Inference time: 11.79 seconds\n",
      "Completed\n",
      "Time taken: 0:00:28.882801\n",
      "Validation score: 0.999978008582936\n",
      "Evaluation score: [5.1813920435961336e-05, 0.9999780058860779]\n",
      "Recall score: 0.999978008582936\n",
      "Precision score: 0.9999780086004023\n",
      "F1 Measure score: 0.9999780085817966\n",
      "ROC-AUC score: 0.9999779508166564\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn import preprocessing\n",
    "import time \n",
    "\n",
    "start = dt.datetime.now()\n",
    "\n",
    "escore = model.evaluate(X_test, Y_test, batch_size=32)\n",
    "\n",
    "# Measure inference time\n",
    "start_time = time.time()\n",
    "pred = model.predict(X_test)\n",
    "end_time = time.time()\n",
    "\n",
    "inference_time = end_time - start_time\n",
    "print(\"Inference time: {:.2f} seconds\".format(inference_time))\n",
    "\n",
    "pred = np.argmax(pred,axis=1)\n",
    "y_eval = np.argmax(Y_test,axis=1)\n",
    "\n",
    "score = metrics.accuracy_score(y_eval, pred)\n",
    "rscore = recall_score(y_eval, pred, average='weighted')\n",
    "ascore = precision_score(y_eval, pred, average='weighted')\n",
    "f1score= f1_score(y_eval, pred, average='weighted') #F1 = 2 * (precision * recall) / (precision + recall) for manual\n",
    "\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(y_eval)\n",
    "y_eval = lb.transform(y_eval)\n",
    "pred = lb.transform(pred)\n",
    "roc_score = roc_auc_score(y_eval, pred)\n",
    "\n",
    "print('Completed')\n",
    "print('Time taken:',dt.datetime.now()-start)\n",
    "\n",
    "print(\"Validation score: {}\".format(score))\n",
    "print(\"Evaluation score: {}\".format(escore))\n",
    "print(\"Recall score: {}\".format(rscore))\n",
    "print(\"Precision score: {}\".format(ascore))\n",
    "print(\"F1 Measure score: {}\".format(f1score))\n",
    "print(\"ROC-AUC score: {}\".format(roc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "633ea4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_by_epoch = 1\n",
    "epochs = range(start_by_epoch, len(loss_values) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f263833",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, acc[start_by_epoch-1:], label='Training accuracy')\n",
    "plt.plot(epochs, val_acc[start_by_epoch-1:], label='Validation accuracy')\n",
    "plt.title('CNN: Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Training', 'Test'], loc='lower right')\n",
    "\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06dac72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.subplot(212)\n",
    "\n",
    "plt.plot(epochs, loss_values[start_by_epoch-1:], label='Training Loss')\n",
    "plt.plot(epochs, val_loss_values[start_by_epoch-1:], label='Validation Loss')\n",
    "plt.title('CNN: Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Training', 'Validation'], loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63727c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.title('CNN: Training and Validation Rate')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966f02ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
